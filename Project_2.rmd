---
title: "Project_2"
author: "Dillon Hong"
date: "3/16/2022"
output:
  html_document:
    toc: yes
    toc_depth: 3
    theme: united
    highlight: tango
    toc_float: true
    number_sections: true
  pdf_document:
    toc: yes
     
---
<style type="text/css">

body{ /* Normal  */
      font-size: 14px;
  }
td {  /* Table  */
  font-size: 8px;
}
h1.title {
  font-size: 38px;
  color: DarkRed;
}
h1 { /* Header 1 */
  font-size: 32px;
  color: DarkBlue;
}
h2 { /* Header 2 */
    font-size: 22px;
  color: DarkBlue;
}
h3 { /* Header 3 */
  font-size: 18px;
  font-family: "Times New Roman", Times, serif;
  color: DarkBlue;
}
code.r{ /* Code block */
    font-size: 14px;
}
pre { /* Code block - determines code spacing between lines */
    font-size: 14px;
}
</style>

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Libraries
```{r}
library(gmodels)
library(caret)
library(class)
library(neuralnet)
library(kernlab)
library(C50)
```
## Data Cleaning and Exploration

```{r}

hotel <- read.csv("hotel_booking.csv")
hotel$arrival_date_week_number <- as.factor(hotel$arrival_date_week_number)


# Delete Unnecessary Columns

hotel$name <- NULL
hotel$email <- NULL
hotel$phone_number <- NULL
hotel$credit_card <- NULL
hotel$arrival_date_year <- NULL
hotel$arrival_date_week_number <- NULL
hotel$arrival_date_day_of_month <- NULL
hotel$reservation_status_date <- NULL
hotel$reservation_status <- NULL

#hotel$country <- ifelse(is.na(hotel$country), "No Country", na.rm = TRUE), hotel$country)

hotel$country <- NULL

#hotel$agent <- ifelse(is.na(hotel$agent), "No Agent", na.rm = TRUE), hotel$agent)
hotel$agent <- NULL

#hotel$company <- ifelse(is.na(hotel$company), "No Company", na.rm = TRUE), hotel$company)
hotel$company <- NULL


hotel <- subset(hotel, hotel == "City Hotel")
hotel$hotel <- NULL
head(hotel, 200)
```

### Check for NAs
```{r}
cbind(
   lapply(
     lapply(hotel, is.na)
     , sum)
   )
```



### Remove NAs from Children Column
```{r}
# Checking for NA values in all of the column data
hotel$children <- ifelse(is.na(hotel$children), median(hotel$children, na.rm = TRUE), hotel$children)

cbind(
   lapply(
     lapply(hotel, is.na)
     , sum)
   )
```


### Randomize and Factorize Data 
```{r}
# Randomize the rows in the data (shuffling the rows)
set.seed(12345)
hotel_random <- hotel[sample(nrow(hotel)),]

hotel_random$arrival_date_month <- as.factor(hotel_random$arrival_date_month)
hotel_random$meal <- as.factor(hotel_random$meal)

hotel_random$market_segment <- as.factor(hotel_random$market_segment)
hotel_random$distribution_channel <- as.factor(hotel_random$distribution_channel)
hotel_random$reserved_room_type <- as.factor(hotel_random$reserved_room_type)
hotel_random$assigned_room_type <- as.factor(hotel_random$assigned_room_type)
hotel_random$deposit_type <- as.factor(hotel_random$deposit_type)
hotel_random$customer_type <- as.factor(hotel_random$customer_type)


# Randomize again for good measure
hotel_random <- hotel_random[sample(nrow(hotel_random)),]
```



### Normalized Data
```{r}
#get rid of factors so we can use KNN
hotelDummy <- as.data.frame(model.matrix (~ . -1, data = hotel_random))
str(hotelDummy)

#Normalize the data
normalize <- function(x) {
  return ((x - min(x)) / (max(x) - min(x)))
}

#Normalize entire dataframe
hotel_norm <- as.data.frame(lapply(hotelDummy[2:ncol(hotelDummy)], normalize))

```
### Test Set

```{r}
test_set <- sample(1:nrow(hotel_random), 0.2*nrow(hotel_random))
```

```{r}
#write.csv(hotel_random[test_set, ]$is_canceled, "test_set_values.csv")
```
### For Knitting Purposes

```{r}
test_set_is_canceled <- read.csv("test_set_values.csv")
test_set_is_canceled <- test_set_is_canceled$x
```

```{r}
#write.csv(hotel_random[test_set, ]$is_canceled, "test_set_values.csv")
```


## Linear Regression Model

### Train and Test Dataset
```{r}
glm_train <- hotel_random[-test_set, ]
glm_test <- hotel_random[test_set, ]

#Now the response (aka Labels) - only the yyes column
glm_train_labels <- hotel_random[-test_set, "is_canceled"]
glm_test_labels <- hotel_random[test_set, "is_canceled"]

```

### Model
```{r}
#glm <- glm(is_canceled ~ lead_time + stays_in_week_nights + adr + is_repeated_guest + previous_cancellations +  meal + previous_bookings_not_canceled +   booking_changes + deposit_type + customer_type + total_of_special_requests, data = glm_train, family = 'binomial')
#summary(glm)
```

### Predictions
```{r}
#for knitting purposes

##glm_prediction <- as.factor(ifelse(glm_prediction>0.5,1,0))
#write.csv(glm_prediction, "hotel_glm_predictions.csv")
```

### Matrix
```{r}
#for knitting purposes
#glm_matrix <- confusionMatrix(glm_prediction, as.factor(glm_test_labels), positive = '1')
glm_prediction <- read.csv("hotel_glm_predictions.csv")
glm_prediction <- glm_prediction$x
glm_matrix <- confusionMatrix(as.factor(glm_prediction), as.factor(test_set_is_canceled), positive = '1')
glm_matrix
```



## KNN Model 

### Train and Test Dataset
```{r}
knn_train <- hotel_norm[-test_set, ]
knn_test <- hotel_norm[test_set, ]

#Now the response (aka Labels) - only the is_canceled column
knn_train_labels <- hotel_random[-test_set, "is_canceled"]
knn_test_labels <- hotel_random[test_set, "is_canceled"]
```

### Model and Predictions
```{r}
#knn <- knn(train = knn_train, test = knn_test, cl = knn_train_labels, k=sqrt(length(knn_train_labels)))
#write.csv(knn, "hotel_knn_predictions.csv")
```

### Confusion Matrix
```{r}
#for knitting purposes
#knn_matrix <- confusionMatrix(as.factor(knn), as.factor(knn_test_labels))
knn <- read.csv("hotel_knn_predictions.csv")
knn <- knn$x
knn_matrix <- confusionMatrix(as.factor(knn), as.factor(test_set_is_canceled))
knn_matrix
```

## ANN Model 

### Train and Test Dataset
```{r}
hotel_norm$is_canceled <- hotel_random$is_canceled

ann_train <- hotel_norm[-test_set, ]
ann_test <- hotel_norm[test_set, ]

#Now the response (aka Labels) - only the yyes column
ann_train_labels <- hotel_norm[-test_set, "is_canceled"]
ann_test_labels <- hotel_norm[test_set, "is_canceled"]
```

### Model
```{r}
#ann <- neuralnet(formula = is_canceled ~ .,data = ann_train)
```

### Prediction
```{r}

#ann_predictions <- predict(ann, ann_test, type="response")
#ann_predictions <- as.factor(ifelse(ann_predictions>0.5,1,0))

#write.csv(ann_predictions, "hotel_ann_predictions.csv")
```

### Confusion Matrix
```{r}
#for knitting purposes
#ann_maxtrix <- confusionMatrix(ann_predictions, as.factor(ann_test_labels))
ann_predictions <- read.csv("hotel_ann_predictions.csv")
ann_predictions <- ann_predictions$x
ann_maxtrix <- confusionMatrix(as.factor(ann_predictions), as.factor(test_set_is_canceled))
ann_maxtrix
```

## SVM

### Train and Test Datasets
```{r}
svm_train <- hotel_random[-test_set, ]
svm_test <- hotel_random[test_set, ]

svm_train_labels <- hotel_random[-test_set, "is_canceled"]
svm_test_labels <- hotel_random[test_set, "is_canceled"]
```

### Model - RBF
```{r}
#svm_rbf <- ksvm(is_canceled ~ ., data = svm_train, kernel = "rbfdot")
```

### Prediction - RBF
```{r}
#svm_predictions_rbf <- predict(svm_rbf, svm_test, type= "response")
#svm_predictions_rbf <- as.factor(ifelse(svm_predictions_rbf > 0.5, 1, 0))

#write.csv(svm_predictions_rbf, "hotel_svm_predictions_rbf.csv")
```

### Confusion Matrix - RBF
```{r}
#for knitting purposes
#svm_matrix_rbf <- confusionMatrix(svm_predictions_rbf, as.factor(svm_test_labels))
svm_predictions_rbf <- read.csv("hotel_svm_predictions_rbf.csv")
svm_predictions_rbf <- svm_predictions_rbf$x
svm_matrix_rbf <- confusionMatrix(as.factor(svm_predictions_rbf), as.factor(test_set_is_canceled))
svm_matrix_rbf
```

### Model - Vanilla 
```{r}
## Commented out as the Vanilla Kernel is the less efficient model

#svm_vanilla <- ksvm(is_canceled ~ ., data = svm_train, kernel = "vanilla")
```

### Prediction - Vanilla
```{r}
#svm_predictions_vanilla <- predict(svm_vanilla, svm_test, type= "response")
#svm_predictions_vanilla <- as.factor(ifelse(svm_predictions_vanilla > 0.5, 1, 0))

#write.csv(svm_predictions_vanilla, "hotel_svm_predictions_vanilla.csv")
```

### Confusion Matrix - Vanilla
```{r}
#svm_matrix_vanilla <- confusionMatrix(svm_predictions_vanilla, as.factor(svm_test_labels))
#svm_matrix_vanilla
```


## Decision Tree

### Train and Test Datasets
```{r}
tree_train <- hotel_random[-test_set, ]
tree_test <- hotel_random[test_set, ]


prop.table(table(tree_train$is_canceled))
prop.table(table(tree_test$is_canceled))
```

### Model
```{r}
#tree <- C5.0(as.factor(is_canceled) ~ ., data = tree_train, trials = 10)
```

### Prediction
```{r}

#c50_hotel_pred <- predict(tree, tree_test)
#write.csv(c50_hotel_pred, "hotel_c50_predictions.csv")
```

### Confusion Matrix
```{r}
#for knitting purposes
#c50_matrix <- confusionMatrix(c50_hotel_pred, as.factor(tree_test$is_canceled))
c50_hotel_pred <- read.csv("hotel_c50_predictions.csv")
c50_hotel_pred <- c50_hotel_pred$x

c50_matrix <- confusionMatrix(as.factor(c50_hotel_pred), as.factor(test_set_is_canceled))
c50_matrix
```

## Stacked Model

```{r}
glm_predictions <- read.csv("hotel_glm_predictions.csv")
knn_predictions <- read.csv("hotel_knn_predictions.csv")
ann_predictions <- read.csv("hotel_ann_predictions.csv")
svm_predictions <- read.csv("hotel_svm_predictions_rbf.csv")
c50_predictions <- read.csv("hotel_c50_predictions.csv")
actuals <- read.csv('test_set_values.csv')

combo_set <- data.frame(actuals$x, glm_predictions$x, knn_predictions$x, ann_predictions$x, svm_predictions$x, c50_predictions$x)
colnames(combo_set) <- c("Actual", "GLM", "KNN", "ANN", "SVM","TREE")

combo_set$Actual <- as.factor(combo_set$Actual)
```

### Test and Train
```{r}
#Set up training data
test_stacked_set <- sample(1:nrow(combo_set), 0.2*nrow(combo_set))

stacked_train <- combo_set[-test_stacked_set,]
stacked_test <- combo_set[test_stacked_set,]

```

### Model
```{r}

#hotel_decision_model <- C5.0(hotel_train[-1], as.factor(hotel_train$is_canceled), trials = 10)
stacked <- C5.0(as.factor(Actual) ~ ., data = stacked_train, trials = 20)
summary(stacked)
plot(stacked)
```

### Prediction
```{r}
stacked_predictions <- predict(stacked, stacked_test)
```

### Confusion Matrix
```{r}
stacked_matrix <- confusionMatrix(stacked_predictions, as.factor(stacked_test$Actual))
stacked_matrix
```

## Conclusion

### Analysis
```{r}
hotel <- read.csv("hotel_booking.csv")
hotel <- subset(hotel, hotel == "City Hotel")
hotel$hotel <- NULL
hotel$arrival_date_day_of_month <- as.factor(hotel$arrival_date_day_of_month)
hotel$arrival_date_year <- as.factor(hotel$arrival_date_year)
hotel$arrival_date_month <- as.factor(hotel$arrival_date_month)
hotel$adr <- as.factor(hotel$adr)
hotel$x <- as.double(1)
data <- aggregate(hotel$adr, list(hotel$arrival_date_day_of_month,hotel$arrival_date_year , hotel$arrival_date_month), FUN = function(x) length(unique(x)))
data
mean(data$x, na.rm = TRUE)

```

### Summary

According to our stacked model prediction, we predicted that 1,261 would cancel out of 3,173 people. That is about a 39.7% cancellation rate. According to our decision tree model there were 6,034 predicted cancel out of 15,866 people resulting in a 38% cancellation rate.

After sorting through the data to connect how many bookings there are per day, we estimate a daily average of 42 people per day. As a result, that is about 16-17 cancellations per day with an over book of about 16-17 per day with 85% confidence on <1% margin of error. This would be used in the case that the hotel does not have the ability to run the model in order to make predictions. This method has a lot of flaws because it generalizes everyday to be the same when in reality some seasons of the year could have more cancellations than others.
  If this method were to be used, cancellation can result in loss potential profit that those rooms could have provided. The mean average daily rate (ADR) is \$105.30. Therefore, with 16-17 average cancellations that is 16-17 rooms open and opportunity cost of \$1,684.80-\$1,790.10 per day or \$614,952-\$653,386.50 per year (assuming 365 days in a year).

For actual usage, the model should be used to directly classify people that are likely to cancel and charge certain rates to those individuals. Some of the others models such as ANN  that give a probability instead of a classification could be useful to also classify individuals. Instead of the 0.50 threshold, a higher threshold could be used because some individuals may have higher probability as a result of having more previous cancellations.
  After classification, a possible solution to counteract this without using overbooking is to charge people classified to cancel a higher rate than ones that aren't. The charges could be up to double to match the opportunity cost of the room if there is a no show. 

